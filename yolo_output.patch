commit ab0465c3ed5150e3962d7ba60aaf81cf45d7b48b
Author: Neo <neo1109.chang@reaktek.com>
Date:   Fri Dec 8 21:28:18 2023 +0800

    Fix export issue
    
    Fix output layer to same with darknet and can be decoded by src/test_model/model_yolo.c

diff --git a/export.py b/export.py
index e44e5d9..a89037c 100644
--- a/export.py
+++ b/export.py
@@ -63,14 +63,14 @@ if __name__ == '__main__':
         model.model[-1].include_nms = True
         y = None
     # TorchScript export
-    try:
-        print('\nStarting TorchScript export with torch %s...' % torch.__version__)
-        f = opt.weights.replace('.pt', '.torchscript.pt')  # filename
-        ts = torch.jit.trace(model, img, strict=False)
-        ts.save(f)
-        print('TorchScript export success, saved as %s' % f)
-    except Exception as e:
-        print('TorchScript export failure: %s' % e)
+    # try:
+    #     print('\nStarting TorchScript export with torch %s...' % torch.__version__)
+    #     f = opt.weights.replace('.pt', '.torchscript.pt')  # filename
+    #     ts = torch.jit.trace(model, img, strict=False)
+    #     ts.save(f)
+    #     print('TorchScript export success, saved as %s' % f)
+    # except Exception as e:
+    #     print('TorchScript export failure: %s' % e)
 
     # ONNX export
     try:
diff --git a/models/yolo.py b/models/yolo.py
index ee250e6..ab697d9 100644
--- a/models/yolo.py
+++ b/models/yolo.py
@@ -44,31 +44,25 @@ class Detect(nn.Module):
         self.training |= self.export
         for i in range(self.nl):
             x[i] = self.m[i](x[i])  # conv
-            bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
-            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()
-
-            if not self.training:  # inference
-                if self.grid[i].shape[2:4] != x[i].shape[2:4]:
-                    self.grid[i] = self._make_grid(nx, ny).to(x[i].device)
-                y = x[i].sigmoid()
-                if not torch.onnx.is_in_onnx_export():
-                    y[..., 0:2] = (y[..., 0:2] * 2. - 0.5 + self.grid[i]) * self.stride[i]  # xy
-                    y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh
-                else:
-                    xy = (y[..., 0:2] * 2. - 0.5 + self.grid[i]) * self.stride[i]  # xy
-                    wh = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i].data  # wh
-                    y = torch.cat((xy, wh, y[..., 4:]), -1)
-                z.append(y.view(bs, -1, self.no))
-
-        if self.training:
-            out = x
-        elif self.end2end:
-            out = torch.cat(z, 1)
-        elif self.include_nms:
-            z = self.convert(z)
-            out = (z, )
-        else:
-            out = (torch.cat(z, 1), x)
+            #bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
+            #x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()
+
+            # if not self.training:  # inference
+            #     if self.grid[i].shape[2:4] != x[i].shape[2:4]:
+            #         self.grid[i] = self._make_grid(nx, ny).to(x[i].device)
+            #     y = x[i].sigmoid()
+            #     if not torch.onnx.is_in_onnx_export():
+            #         y[..., 0:2] = (y[..., 0:2] * 2. - 0.5 + self.grid[i]) * self.stride[i]  # xy
+            #         y[..., 2:4] = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i]  # wh
+            #     else:
+            #         xy = (y[..., 0:2] * 2. - 0.5 + self.grid[i]) * self.stride[i]  # xy
+            #         wh = (y[..., 2:4] * 2) ** 2 * self.anchor_grid[i].data  # wh
+            #         y = torch.cat((xy, wh, y[..., 4:]), -1)
+            #     z.append(y.view(bs, -1, self.no))
+            y = x[i].sigmoid()
+            z.append(y)
+
+        out = z
 
         return out
 
diff --git a/weights/yolov7-tiny.onnx b/weights/yolov7-tiny.onnx
index b576853..5e9e0c3 100644
Binary files a/weights/yolov7-tiny.onnx and b/weights/yolov7-tiny.onnx differ

commit daa915d804fae2eff85450436a35e23a0f3688c2
Author: Neo <neo1109.chang@reaktek.com>
Date:   Thu Jul 28 16:37:05 2022 +0800

    Add converted onnx model
    
    Can use acuity to import

diff --git a/export.py b/export.py
index 8fd0d6e..e44e5d9 100644
--- a/export.py
+++ b/export.py
@@ -79,7 +79,7 @@ if __name__ == '__main__':
         print('\nStarting ONNX export with onnx %s...' % onnx.__version__)
         f = opt.weights.replace('.pt', '.onnx')  # filename
         model.eval()
-        output_names = ['classes', 'boxes'] if y is None else ['output']
+        output_names = ['classes', 'boxes'] if y is None else ['output_1', 'output_2', 'output_3']
         if opt.grid and opt.end2end:
             print('\nStarting export end2end onnx model for %s...' % 'TensorRT' if opt.max_wh is None else 'onnxruntime')
             model = End2End(model,opt.topk_all,opt.iou_thres,opt.conf_thres,opt.max_wh,device)
